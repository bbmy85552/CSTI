# 专精特新企业科创评分模型训练全流程解析

## 功能概述
该流程面向 5956 家专精特新企业，构建「输入企业画像 → 输出科创水平分数」的预测模型。整体步骤涵盖数据清洗、特征工程、多模型对比、最佳模型评估与持久化，并提供推理脚本用于给定企业要素后快速获得预测分与同档位均值参考。

## 数据资产
- **原始来源**：`basic.xlsx`、`kechuang-data.xlsx` 与 `Latitude_longitude.xlsx`（位于 `预处理-建模-可视化/预处理/data`）。
- **清洗结果**：`预处理-建模-可视化/result.CSV`，字段包括企业基础信息、资本换算、科创评分、专利统计与五维评价分值。
- **建模输入**：`result.CSV` 在特征工程阶段被进一步处理，删除极度稀疏/无关列，并对 `city_district`、`type`、`industry_lv2` 做独热编码。

## 数据预处理流水
数据清洗脚本 `预处理-建模-可视化/预处理/data_preprocess.py` 负责把三个源表融合为统一的训练数据，关键步骤如下：
1. **缺失值整合**：先处理核心指标（如参保人数、超越同行百分比），把 `-`、`flase` 等异常标记统一替换为 `pd.NA`，确保后续可用 `describe()` / `isnull()` 监控缺口（行 13-41）。
2. **企业名称对齐**：通过正则剔除企业曾用名、附加地理信息等括号内容，确保三张表 `company_name` 字段一致后再执行内连接（行 52-83）。
3. **字段规范化**：将原列表头映射为英文名，并拼接 `city + district → city_district`，方便模型直接使用（行 87-112）。
4. **注册资本统一币种**：构建汇率字典，将包含“人民币/港元/美元/欧元/日元/加元/万”后缀的资本值转为 `capital_cny_w`，保留“万元人民币”刻度（行 113-174）。
5. **地理异常过滤**：以多边形圈定粤港澳大湾区范围，对超出边界或特定异常 id（5558、4549）标记经纬度为空值，避免影响空间特征（行 177-214）。
6. **拆分五维评分**：把 `five_score` 拆成创新能力、研发实力、行业潜力、成长性、科创资质五列，作为数值特征直接建模（行 216-234）。
7. **字段重排/导出**：最终输出 28 列训练集至 `result.csv`，为建模阶段提供整洁的结构化数据（行 235-242）。

## 特征工程
建模脚本在读取 `result.CSV` 后执行一致的处理逻辑：
- 删除与目标无强关联且容易造成信息泄漏的列，例如 `company_name`、`business_scope`、经纬度等（`GradientBoosting2joblib.py` 行 18-22；`Model MSE comparison.py` 行 23-27）。
- 使用 `pd.get_dummies` 对 `city_district`、`type`、`industry_lv2` 进行独热编码，并统一设置 `dtype='uint8'` 控制内存占用（同上行 24-35）。
- 将 `score` 作为监督学习目标，其余列组成特征矩阵 `X`。

## 多模型对比
`预处理-建模-可视化/model/Model MSE comparison.py`（行 33-121）基于相同的特征矩阵，训练并评估七种模型，统一使用 `train_test_split(test_size=0.2, random_state=42)`：
- 线性、岭、套索、弹性网回归。
- 决策树、随机森林、梯度提升回归。

脚本末尾保留了各模型 MSE（单位：分²）的静态结果，可见树集成明显优于线性模型：
```
Linear 103.76 | Ridge 101.40 | Lasso 104.68 | Elastic Net 103.56
Decision Tree 18.13 | Random Forest 10.37 | Gradient Boosting 9.69
```
因此后续阶段聚焦梯度提升树（GBRT）。

## 梯度提升树训练与评估
`GradientBoosting_show.py` 在相同的数据拆分下训练 `GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)`，并输出全套指标（行 38-72）：
- **MSE ≈ 9.69，RMSE ≈ 3.11**，显著降低误差。
- **MAE** 与 **R²** 同时打印，用于衡量平均偏离和拟合优度（行 50-64）。
- 5 折交叉验证的 `mean_cv_mse` / `mean_cv_rmse` 进一步验证泛化能力（行 66-71）。

该脚本还计算特征重要性，先获取所有特征的 `feature_importances_`，再把 `industry_lv2_*`、`city_district_*`、`type_*` 聚合为三大类，混合展示数值和类别特征的贡献度（行 73-118）。

## 最终模型导出
`GradientBoosting2joblib.py`（行 27-60）基于同样的管线训练 GBRT 后，将关键信息序列化：
1. `columns_order.joblib` 记录特征列顺序，确保推理时的独热编码列与训练一致。
2. `gbt_model.joblib` 保存训练好的模型对象，可跨进程加载。

## 推理与区间诊断
`predict.py` 展示了完整的推理脚本（行 4-67）：
1. 加载列顺序与模型；构造单条企业画像（数值特征 + 原始分类字段）。
2. 对输入执行独热编码，并补齐缺失列后按训练顺序重排再预测（行 23-39）。
3. 根据预测得分所在区间（46-72、72-78、78-86、86-99）筛选历史样本，输出该档企业在核心特征上的均值，用于对标建议（行 43-65）。

## 端到端流程回顾
1. **数据清洗**：借助 `data_preprocess.py` 将多源企业信息对齐、补齐、转换为建模友好的结构。
2. **特征工程**：统一删除无关字段，落地独热编码，获得数值化特征矩阵。
3. **模型对比**：横向评估七类回归模型，确定梯度提升树的性能优势。
4. **模型精炼**：对 GBRT 做指标评估、交叉验证、特征重要性分析，并生成误差/残差可视化（留存于 `模型指标结果` 目录）。
5. **成果交付**：使用 `joblib` 持久化模型与列序，并提供 `predict.py` 作为推理入口，实现从输入企业画像到预测得分 + 档位均值的闭环。

通过以上链路，可快速从原始 Excel 数据走到可部署的评分模型，实现“预处理 → 建模 → 预测”全生命周期的自动化。

